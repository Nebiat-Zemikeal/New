{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6aQwwv7z/wmFnYDXsdwG/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nebiat-Zemikeal/New/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "21A9T-ZEtXur"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras import layers, callbacks, utils, datasets, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Set a random seed to maintain similar values\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from keras\n",
        "# x = inputs and y = outputs\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "# Numerical operations (e.g. CNNs) prefer values between 0, 1 or -1, 1\n",
        "# We must scale the values from 255 (default inputs) to 0-1 (CNN inputs)\n",
        "# Note that we also convert the arrays to float32,\n",
        "#   this could be float16/float8 for speed or float64 for accuracy, etc\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Conv2D-nets require 4D inputs: batch, row, col, color\n",
        "# Unfortunately, MNIST does not provide a color dimension: it's greysca\n",
        "# Therefore, we add the color dimensions to represent greyscale\n",
        "COLOR_DIM = -1\n",
        "x_train = np.expand_dims(x_train, axis=COLOR_DIM)\n",
        "x_test = np.expand_dims(x_test, axis=COLOR_DIM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkTL_FG5t65J",
        "outputId": "f7a0b798-aac6-4dce-cc18-9b08f4d2703b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = np.unique(y_train).__len__()  # 10\n",
        "img_shape = x_train[0].shape  # 28, 28, 1"
      ],
      "metadata": {
        "id": "J3eH_ZNluFLI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample of labels before one-hot encoding\")\n",
        "print(np.random.choice(y_train.ravel(), size=5))\n",
        "\n",
        "# tf.keras function to transform integer labels to one-hot encodings\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"Sample of labels after one-hot encoding\")\n",
        "print(y_train[np.random.choice(range(y_train.shape[0]), size=5)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXLzs5ltuLIO",
        "outputId": "0b1dcd09-4317-42ac-f7dc-cb953b8df26b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of labels before one-hot encoding\n",
            "[4 0 0 8 3]\n",
            "Sample of labels after one-hot encoding\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confirm Shape\")\n",
        "print(f\"x_train shape: {x_train.shape}\")  # (60000, 28, 28, 1)\n",
        "print(f\"x_test shape : {x_test.shape}\")  # (10000, 28, 28, 1)\n",
        "\n",
        "print(\"Confirm Samples\")\n",
        "print(f\"train samples: {x_train.shape[0]}\")  # 60000\n",
        "print(f\"test samples : {x_test.shape[0]}\")  # 10000\n",
        "\n",
        "print(\"Confirm Train Range\")\n",
        "print(f\"x_train min: {x_train.min()}\")  # 0.0\n",
        "print(f\"x_train max: {x_train.max()}\")  # 1.0\n",
        "\n",
        "print(\"Confirm Test Range\")\n",
        "print(f\"x_test min: {x_test.min()}\")  # 0.0\n",
        "print(f\"x_test max: {x_test.max()}\")  # 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDiPHCTUuOq9",
        "outputId": "66372e07-1a01-40c4-810b-e1b45d407758"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confirm Shape\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "x_test shape : (10000, 28, 28, 1)\n",
            "Confirm Samples\n",
            "train samples: 60000\n",
            "test samples : 10000\n",
            "Confirm Train Range\n",
            "x_train min: 0.0\n",
            "x_train max: 1.0\n",
            "Confirm Test Range\n",
            "x_test min: 0.0\n",
            "x_test max: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confirm Shape\")\n",
        "print(f\"y_train shape: {y_train.shape}\")  # (60000, 10)\n",
        "print(f\"y_test shape : {y_test.shape}\")  # (10000, 10)\n",
        "\n",
        "print(\"Confirm Samples\")\n",
        "print(f\"train samples: {y_train.shape[0]}\")  # 60000\n",
        "print(f\"test samples : {y_test.shape[0]}\")  # 10000\n",
        "\n",
        "print(\"Confirm Train Range\")\n",
        "print(f\"y_train min: {y_train.min()}\")  # 0.0\n",
        "print(f\"y_train max: {y_train.max()}\")  # 1.0\n",
        "\n",
        "print(\"Confirm Test Range\")\n",
        "print(f\"y_test min: {y_test.min()}\")  # 0.0\n",
        "print(f\"y_test max: {y_test.max()}\")  # 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjzc4O2iuS-J",
        "outputId": "97cf1832-5189-49e8-e9ff-fc859cbaa55c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confirm Shape\n",
            "y_train shape: (60000, 10)\n",
            "y_test shape : (10000, 10)\n",
            "Confirm Samples\n",
            "train samples: 60000\n",
            "test samples : 10000\n",
            "Confirm Train Range\n",
            "y_train min: 0.0\n",
            "y_train max: 1.0\n",
            "Confirm Test Range\n",
            "y_test min: 0.0\n",
            "y_test max: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the layers for the model\n",
        "input_layer = layers.Input(shape=img_shape)\n",
        "hidden_layer1 = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")\n",
        "hidden_layer2 = layers.MaxPooling2D(pool_size=(2, 2))\n",
        "hidden_layer3 = layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\")\n",
        "hidden_layer4 = layers.MaxPooling2D(pool_size=(2, 2))\n",
        "hidden_layer5 = layers.Flatten()\n",
        "hidden_layer6 = layers.Dropout(0.5)\n",
        "output_layer = layers.Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "# Build the Sequential model\n",
        "model = Sequential([\n",
        "    input_layer,\n",
        "    hidden_layer1,\n",
        "    hidden_layer2,\n",
        "    hidden_layer3,\n",
        "    hidden_layer4,\n",
        "    hidden_layer5,\n",
        "    hidden_layer6,\n",
        "    output_layer\n",
        "])"
      ],
      "metadata": {
        "id": "5BMlU_NOuXJN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define how we will build the model\n",
        "model = models.Sequential(name='MNIST_CNN_Tutorial')\n",
        "\n",
        "# Create the input layer to understand the shape of each image and batch-size\n",
        "model.add(\n",
        "    layers.Input(\n",
        "        shape=img_shape,\n",
        "        # batch_size=batch_size,\n",
        "        name='Image_Batch_Input_Layer',\n",
        "    )\n",
        ")\n",
        "\n",
        "# Add the firest convolution layer with 32 filters\n",
        "model.add(\n",
        "    layers.Conv2D(\n",
        "        filters=nfilters_hidden1,\n",
        "        kernel_size=kernel_shape,\n",
        "        activation=activation,\n",
        "        padding=padding,\n",
        "        strides=strides,\n",
        "        name='First_Conv2D_Layer'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Reduce the dimensionality after the first Conv-layer w/ MaxPool2D\n",
        "model.add(\n",
        "    layers.MaxPooling2D(\n",
        "        pool_size=pool_shape,\n",
        "        name=\"First_MaxPool2D_Layer\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Add the firest convolution layer with 64 filters\n",
        "model.add(\n",
        "    layers.Conv2D(\n",
        "        filters=nfilters_hidden2,\n",
        "        kernel_size=kernel_shape,\n",
        "        activation=activation,\n",
        "        padding=padding,\n",
        "        strides=strides,\n",
        "        name='Second_Conv2D_Layer'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Reduce the dimensionality after the second Conv-layer w/ MaxPool2D\n",
        "model.add(\n",
        "    layers.MaxPooling2D(\n",
        "        pool_size=pool_shape,\n",
        "        name=\"Second_MaxPool2D_Layer\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Convert the 2D outputs to a 1-D vector in preparation for label prediction\n",
        "model.add(\n",
        "    layers.Flatten(\n",
        "        name=\"Flatten_from_Conv2D_to_Dense\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Dropout 50% of the neurons from the Conv+Flatten layers to regulate\n",
        "model.add(\n",
        "    layers.Dropout(\n",
        "        rate=dropout_rate,\n",
        "        name=\"Dropout_from_Dense_to_Output\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Compute the weighted-logistic for each possible label in one-hot encoding\n",
        "model.add(\n",
        "    layers.Dense(\n",
        "        units=num_classes,\n",
        "        activation=\"softmax\",\n",
        "        name=\"n-Dimensional_Logistic_Output_Layer\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "VBgRJXuQxzHM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vlf7HxZ50dmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41b56281"
      },
      "source": [
        "# Define model parameters\n",
        "nfilters_hidden1 = 32\n",
        "nfilters_hidden2 = 64\n",
        "kernel_shape = (3, 3)\n",
        "activation = \"relu\"\n",
        "padding = \"valid\"\n",
        "strides = (1, 1)\n",
        "pool_shape = (2, 2)\n",
        "dropout_rate = 0.5"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model: \"MNIST_CNN_Tutorial\""
      ],
      "metadata": {
        "id": "7AkSoWcu0ko1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "eTavPqXv0q6e"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Modules\n",
        "from tensorflow.keras import layers, utils, datasets, models\n",
        "import numpy as np # Added numpy import\n",
        "\n",
        "# Load Data\n",
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "x_train, x_test = preprocess(x_train, x_test)\n",
        "\n",
        "# Encode labels\n",
        "y_train, y_test = one_hot_encoding(y_train, y_test)\n",
        "\n",
        "# Create Model\n",
        "img_shape = x_train[0].shape # Get img_shape after preprocessing\n",
        "num_classes = np.unique(y_train.argmax(axis=1)).__len__() # Get num_classes from one-hot encoded labels\n",
        "model = create_cnn_model(img_shape, num_classes)\n",
        "\n",
        "# Compile Model\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "5np53q1S000O"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3fTvH8_04jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3edfae0c"
      },
      "source": [
        "def preprocess(x_train, x_test):\n",
        "    \"\"\"Scales and reshapes the image data.\"\"\"\n",
        "    x_train = x_train.astype(\"float32\") / 255\n",
        "    x_test = x_test.astype(\"float32\") / 255\n",
        "    COLOR_DIM = -1\n",
        "    x_train = np.expand_dims(x_train, axis=COLOR_DIM)\n",
        "    x_test = np.expand_dims(x_test, axis=COLOR_DIM)\n",
        "    return x_train, x_test\n",
        "\n",
        "def one_hot_encoding(y_train, y_test):\n",
        "    \"\"\"Converts integer labels to one-hot encoded labels.\"\"\"\n",
        "    num_classes = np.unique(y_train).__len__()\n",
        "    y_train = utils.to_categorical(y_train, num_classes)\n",
        "    y_test = utils.to_categorical(y_test, num_classes)\n",
        "    return y_train, y_test\n",
        "\n",
        "def create_cnn_model(img_shape, num_classes):\n",
        "    \"\"\"Creates and returns a CNN model.\"\"\"\n",
        "    # Define model parameters (assuming these are already defined in the notebook)\n",
        "    nfilters_hidden1 = 32\n",
        "    nfilters_hidden2 = 64\n",
        "    kernel_shape = (3, 3)\n",
        "    activation = \"relu\"\n",
        "    padding = \"valid\"\n",
        "    strides = (1, 1)\n",
        "    pool_shape = (2, 2)\n",
        "    dropout_rate = 0.5\n",
        "\n",
        "    model = models.Sequential(name='MNIST_CNN_Tutorial')\n",
        "\n",
        "    model.add(layers.Input(shape=img_shape, name='Image_Batch_Input_Layer'))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=nfilters_hidden1, kernel_size=kernel_shape, activation=activation, padding=padding, strides=strides, name='First_Conv2D_Layer'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=pool_shape, name=\"First_MaxPool2D_Layer\"))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=nfilters_hidden2, kernel_size=kernel_shape, activation=activation, padding=padding, strides=strides, name='Second_Conv2D_Layer'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=pool_shape, name=\"Second_MaxPool2D_Layer\"))\n",
        "\n",
        "    model.add(layers.Flatten(name=\"Flatten_from_Conv2D_to_Dense\"))\n",
        "    model.add(layers.Dropout(rate=dropout_rate, name=\"Dropout_from_Dense_to_Output\"))\n",
        "    model.add(layers.Dense(units=num_classes, activation=\"softmax\", name=\"n-Dimensional_Logistic_Output_Layer\"))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate Model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMebGkON0-2A",
        "outputId": "9b1c6bfb-1f07-45d8-cf72-11aaa9a21425"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.8514 - loss: 0.4798 - val_accuracy: 0.9835 - val_loss: 0.0567\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9712 - loss: 0.0916 - val_accuracy: 0.9883 - val_loss: 0.0432\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.9781 - loss: 0.0683 - val_accuracy: 0.9898 - val_loss: 0.0374\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - accuracy: 0.9818 - loss: 0.0581 - val_accuracy: 0.9907 - val_loss: 0.0326\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.9841 - loss: 0.0508 - val_accuracy: 0.9933 - val_loss: 0.0299\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.9865 - loss: 0.0433 - val_accuracy: 0.9902 - val_loss: 0.0336\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - accuracy: 0.9876 - loss: 0.0425 - val_accuracy: 0.9920 - val_loss: 0.0319\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.9880 - loss: 0.0401 - val_accuracy: 0.9907 - val_loss: 0.0307\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 24ms/step - accuracy: 0.9885 - loss: 0.0368 - val_accuracy: 0.9922 - val_loss: 0.0315\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.9885 - loss: 0.0347 - val_accuracy: 0.9903 - val_loss: 0.0322\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0322\n",
            "Test Loss: 0.02644968219101429, Test Accuracy: 0.9909999966621399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5  # How many iterations should we cycle over the entire MNIST dataset\n",
        "validation_split = 0.1  # how many images to hold out per epoch: 10%\n",
        "batch_size = 128  # nominal use cases: 32, 64, 128, 256, 512\n",
        "early_stopping = callbacks.EarlyStopping(patience=5)\n",
        "\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=validation_split,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdqVQEp72Emi",
        "outputId": "571fa7df-6d27-40e5-9572-2a5bef58a24e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 85ms/step - accuracy: 0.9902 - loss: 0.0294 - val_accuracy: 0.9930 - val_loss: 0.0303\n",
            "Epoch 2/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 86ms/step - accuracy: 0.9920 - loss: 0.0251 - val_accuracy: 0.9928 - val_loss: 0.0292\n",
            "Epoch 3/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 86ms/step - accuracy: 0.9929 - loss: 0.0225 - val_accuracy: 0.9932 - val_loss: 0.0289\n",
            "Epoch 4/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 83ms/step - accuracy: 0.9924 - loss: 0.0241 - val_accuracy: 0.9925 - val_loss: 0.0274\n",
            "Epoch 5/5\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - accuracy: 0.9929 - loss: 0.0214 - val_accuracy: 0.9928 - val_loss: 0.0280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The results below may differ from the table above because of randomised\n",
        "#  initial conditions and randomised processes during fitting: e.g., `Dropout`\n",
        "for key, val in history.history.items():\n",
        "    print(f'{key:>12}: {np.round(val, 3)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mqy8bt34H_L",
        "outputId": "0100cf26-5b02-4d8b-aa11-caf5e70ecade"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    accuracy: [0.991 0.992 0.993 0.993 0.993]\n",
            "        loss: [0.027 0.025 0.023 0.023 0.023]\n",
            "val_accuracy: [0.993 0.993 0.993 0.993 0.993]\n",
            "    val_loss: [0.03  0.029 0.029 0.027 0.028]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
        "train_score = model.evaluate(x_train, y_train, verbose=0)"
      ],
      "metadata": {
        "id": "aUPnnvF15d5o"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'     Test loss'}: {test_score[0]}\")\n",
        "print(f\"{'    Train loss'}: {train_score[0]}\")\n",
        "print()\n",
        "print(f\"{' Test accuracy'}: {test_score[1]}\")\n",
        "print(f\"{'Train accuracy'}: {train_score[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jopsp9yk5j9s",
        "outputId": "bd64a1cc-edb3-46e5-a0ec-a1b38d14b5f3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Test loss: 0.0208812914788723\n",
            "    Train loss: 0.010287669487297535\n",
            "\n",
            " Test accuracy: 0.9927999973297119\n",
            "Train accuracy: 0.9971333146095276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test loss: {test_score[0]:.5f}\")\n",
        "print(f\"Train loss: {train_score[0]:.5f}\")\n",
        "print()\n",
        "print(f\"Test accuracy: {test_score[1]:.2%}\")\n",
        "print(f\"Train accuracy: {train_score[1]:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBb8Dyct5puD",
        "outputId": "3c22357b-3b1b-4ce2-9c67-53a092f58c30"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.02088\n",
            "Train loss: 0.01029\n",
            "\n",
            "Test accuracy: 99.28%\n",
            "Train accuracy: 99.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = model.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp29zZfL5uyQ",
        "outputId": "8e677231-5d9f-4f14-f4b5-38c29dc234bd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_samples(\n",
        "    images=x_test,\n",
        "    labels=y_test,\n",
        "    predictions=pred_test,\n",
        "    n_rows=7,\n",
        "    n_cols=7,\n",
        "    figsize=(8, 8)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "IpEMeEm955P1",
        "outputId": "af17ed77-8fdd-4994-b934-c8e1ad6c1c57"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plot_samples' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1061534051.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plot_samples(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_samples' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jXaqKetI6DWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85b26b36"
      },
      "source": [
        "def plot_samples(images, labels, predictions=None, n_rows=5, n_cols=5, figsize=(10, 10)):\n",
        "    \"\"\"Plots sample images with their labels and optional predictions.\"\"\"\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(n_rows * n_cols):\n",
        "        plt.subplot(n_rows, n_cols, i + 1)\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "        if predictions is not None:\n",
        "            predicted_label = np.argmax(predictions[i])\n",
        "            true_label = np.argmax(labels[i])\n",
        "            color = 'green' if predicted_label == true_label else 'red'\n",
        "            plt.title(f\"True: {true_label}\\nPred: {predicted_label}\", color=color)\n",
        "        else:\n",
        "            true_label = np.argmax(labels[i])\n",
        "            plt.title(f\"True: {true_label}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# This is the expected properties for MNIST\n",
        "num_classes = 10  # 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
        "img_shape = 28, 28, 1  # 28 rows, 28 columns, 1 color -- grayscale\n",
        "\"\"\"\n",
        "\n",
        "# load data from keras\n",
        "# x = inputs and y = outputs\n",
        "\n",
        "dataset = 'mnist'  # 'mnist'  # 'fashion_mnist'  # 'cifar10'\n",
        "if dataset == 'mnist':\n",
        "    (x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "if dataset == 'fashion_mnist':\n",
        "    (x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()\n",
        "if dataset == 'cifar10':\n",
        "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "# Numerical operatoins (e.g. CNNs) prefer values between 0, 1 or -1, 1\n",
        "# We must scale the values from 255 (default inputs) to 0-1 (CNN inputs)\n",
        "# Note that we also convert the arrays to float32,\n",
        "#   this could be float16/float8 for speed for float64 for accuracy, etc\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Conv2D-nets require 4D inputs: batch, row, col, color\n",
        "if np.ndim(x_train) == 3: # no color dimension\n",
        "    # Add the color dimensions to represent greyscale\n",
        "    COLOR_DIM = -1\n",
        "    x_train = np.expand_dims(x_train, axis=COLOR_DIM)\n",
        "    x_test = np.expand_dims(x_test, axis=COLOR_DIM)\n"
      ],
      "metadata": {
        "id": "We03wJIn6MWZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XSVwvJKO6uYt"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "acL7OmYE7Bcr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}